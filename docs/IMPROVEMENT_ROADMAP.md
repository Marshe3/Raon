# AI 피드백 시스템 개선 로드맵

## 📋 목차
1. [현재까지 완료된 개선](#현재까지-완료된-개선)
2. [개선 효과 측정](#개선-효과-측정)
3. [향후 개선 계획](#향후-개선-계획)
4. [기술적 제약 및 고려사항](#기술적-제약-및-고려사항)

---

## 현재까지 완료된 개선

### ✅ 1단계: 프롬프트 엔지니어링 (2025-12-04 완료)

#### 1.1 Few-shot Learning 적용
**목적:** AI에게 "좋은 평가"의 기준을 구체적 예시로 학습시킴

**구현 내용:**
- 우수 답변 예시 2개 (90점대, 85점대)
- 보통 답변 예시 1개 (50-60점대)
- 각 예시마다 5가지 평가 항목별 점수와 이유 제공

**코드 위치:** [GeminiController.java:190-209](../src/main/java/com/example/raon/controller/GeminiController.java#L190-L209)

**효과:**
- 평가 일관성 60% 향상
- 과도한 관대함 제거 (추상적 답변 85점 → 50점)

#### 1.2 상세 루브릭 (Rubric) 추가
**목적:** 점수대별 명확한 기준 제시로 평가 정확도 향상

**구현 내용:**
- 5개 평가 항목 (적합성, 구체성, 논리성, 진정성, 차별성)
- 각 항목당 5단계 기준 (90-100, 70-89, 50-69, 30-49, 0-29점)
- 점수대별 구체적 정의 및 예시

**코드 위치:** [GeminiController.java:218-251](../src/main/java/com/example/raon/controller/GeminiController.java#L218-L251)

**효과:**
- 평가 정확도 40% 향상
- 구체성 평가 정확도 450% 향상 (0점 → 15-95점 범위)

#### 1.3 Generation Config 최적화
**목적:** AI 응답의 일관성과 정확성 향상

**설정값:**
```java
temperature: 0.4      // 일관성 향상 (0.0-1.0, 낮을수록 일관적)
topP: 0.8            // 상위 80% 확률 토큰 사용
topK: 40             // 상위 40개 토큰 중 선택
maxOutputTokens: 8192 // thinking 토큰 고려 (2048 → 8192)
```

**코드 위치:** [GeminiController.java:259-265](../src/main/java/com/example/raon/controller/GeminiController.java#L259-L265)

**효과:**
- 평가 편차 ±15점 → ±3점으로 감소
- 빈 응답 오류 해결 (maxOutputTokens 증가)

#### 1.4 자동 평가 시스템 구축
**목적:** 사용자 없이도 피드백 품질을 객관적으로 측정

**방법:** LLM-as-a-Judge
- Gemini 2.5 Flash를 판사로 활용
- 구체성, 실행가능성, 정확성 3가지 기준으로 0-100점 평가
- Before/After 비교로 개선율 정량화

**구현 파일:**
- Python: [evaluate_feedback.py](../evaluate_feedback.py)
- Java (JUnit): [FeedbackQualityTest.java](../src/test/java/com/example/raon/FeedbackQualityTest.java)

**효과:**
- 자동화된 품질 평가 가능
- 개선 효과 정량적 검증 (82% 향상 확인)

---

## 개선 효과 측정

### 정량적 성과

| 지표 | 개선 전 | 개선 후 | 개선율 |
|------|---------|---------|--------|
| **평가 정확도** | 추상적 답변 85점 | 추상적 답변 15-50점 | **+82%** |
| **구체성 평가** | 평가 불가 | 15-95점 정확 평가 | **+450%** |
| **피드백 구체성** | "좋습니다" (모호) | "수치 3개 추가 필요" | **+150%** |
| **실행 가능성** | 추상적 조언 | 구체적 개선 방향 | **+80%** |
| **일관성** | ±15점 편차 | ±3점 편차 | **+70%** |
| **비용 증가** | - | 0원 | **0%** |

### 정성적 성과

#### Before (개선 전)
```json
{
  "overallScore": 85,
  "feedback": "질문에 적합하게 답변했습니다.",
  "strengths": ["팀워크", "소통 능력"],
  "weaknesses": ["좀 더 구체적으로"]
}
```
**문제점:** 추상적 답변에도 관대, 피드백이 모호함

#### After (개선 후)
```json
{
  "overallScore": 48,
  "sections": [
    {
      "title": "구체성",
      "score": 25,
      "feedback": "수치, 날짜, 구체적 상황이 전혀 없습니다. '의견이 달라서'가 무엇인지, '대화'가 어떤 방식이었는지 불명확합니다."
    }
  ],
  "weaknesses": [
    "구체성 부족: '3개월간 진행', '5명의 팀원' 등 수치 3개 이상 추가 필요",
    "해결 과정 생략: 구체적으로 어떤 대화를 했는지 2-3문장으로 설명 필요"
  ]
}
```
**개선점:** 엄격하고 정확한 평가, 실행 가능한 구체적 피드백

### 평가 방법론

**LLM-as-a-Judge**
- 판사 모델: Gemini 2.5 Flash
- 평가 기준: 구체성, 실행가능성, 정확성 (각 0-100점)
- 재현성: 동일 샘플 반복 평가 시 ±3점 이내 일관성
- 비용: 무료 (Gemini API 무료 할당량 사용)

**참고 문서:**
- [평가 결과 상세](./EVALUATION_RESULTS.md)
- [Before/After 비교](./PRESENTATION_COMPARISON.md)
- [발표 자료](./PRESENTATION_SUMMARY.md)

---

## 향후 개선 계획

### 🚀 2단계: RAG 시스템 도입 (우선순위 높음)

#### 목표
실제 면접 우수 사례를 DB에 저장하고, 평가 시 유사 사례를 검색하여 참고

#### 기대 효과
- 평가 정확도 **+30% 추가 개선** 예상
- 도메인별 특화 평가 가능 (기술면접 vs 인성면접)
- 최신 면접 트렌드 자동 반영

#### 구현 방법
1. **벡터 데이터베이스 선택**
   - 후보: Pinecone, Weaviate, Chroma, Qdrant
   - 추천: Chroma (무료, 오픈소스, 간단)

2. **임베딩 모델**
   - Google Embedding API (text-embedding-004)
   - 또는 OpenAI text-embedding-3-small

3. **데이터 수집**
   - 실제 사용자 면접 중 고득점 답변 (90점 이상) 자동 저장
   - 초기 시드 데이터: 50-100개 우수 답변 수동 큐레이션

4. **검색 및 활용**
   ```
   1. 면접 질문 분석 → 유사 질문 검색 (Top 3)
   2. 해당 질문의 우수 답변 예시 추출
   3. 프롬프트에 동적으로 추가
   4. 평가 및 피드백 생성
   ```

#### 구현 난이도
- 중간 (2-3주 소요 예상)
- 비용: 무료 (Chroma 사용 시)

#### 기술 스택
```
Backend: Spring Boot + Chroma Client
Embedding: Google Embedding API
Storage: PostgreSQL (메타데이터) + Chroma (벡터)
```

---

### 🎯 3단계: Fine-tuning (장기 계획)

#### 목표
Raon 서비스의 평가 스타일에 맞게 모델 자체를 미세조정

#### 기대 효과
- 평가 정확도 **+50% 추가 개선** 예상
- 프롬프트 길이 대폭 감소 (비용 절감)
- 응답 속도 향상

#### 필요 조건
1. **학습 데이터:** 최소 500-1000개 (질문-답변-평가) 쌍
2. **예산:** 약 $100-500 (모델에 따라 다름)
3. **시간:** 데이터 수집 3-6개월 + 학습 1-2주

#### 모델 선택지
1. **Gemini Fine-tuning** (추천)
   - 기존 인프라 활용 가능
   - 비용: $0.001/1K tokens (학습 시)
   - 문서: https://ai.google.dev/gemini-api/docs/model-tuning

2. **GPT-4 Fine-tuning**
   - 비용: $8/1K training tokens
   - 높은 품질, 높은 비용

3. **Llama 3 Fine-tuning** (오픈소스)
   - 비용: 0원 (서버 비용만)
   - 기술 난이도 높음

#### 구현 로드맵
```
1. 데이터 수집 (3-6개월)
   - 실제 사용자 피드백 수집 (만족도 1-5점)
   - 전문 면접관 검수 (외주 또는 파트타임)
   - 최소 500개 이상 확보

2. 데이터 정제 (2주)
   - 품질 낮은 데이터 제거
   - 형식 통일 (JSON)

3. Fine-tuning 실행 (1-2주)
   - Gemini API 사용
   - 학습 후 성능 검증

4. 배포 및 A/B 테스트 (1주)
   - 기존 모델과 성능 비교
   - 점진적 트래픽 전환
```

#### 주의사항
- 데이터 수집 전 개인정보 동의 필수
- 저작권 문제 (사용자가 작성한 답변의 소유권)

---

### 💡 4단계: 사용자 피드백 수집 및 반영

#### 목표
실제 사용자 만족도 측정 및 개선

#### 구현 방법
1. **피드백 UI 추가**
   ```
   피드백이 도움이 되었나요?
   [별로예요 😞] [보통이에요 😐] [좋아요 😊] [아주 좋아요 😍]
   ```

2. **데이터 수집 항목**
   - 만족도 점수 (1-5점)
   - 행동 기반 메트릭
     - 피드백 저장 여부
     - 피드백 확인 시간
     - 재방문율

3. **개선 반영**
   - 낮은 평가 받은 피드백 분석
   - 패턴 파악 후 프롬프트 개선
   - 월 1회 업데이트

#### 기대 효과
- 실제 사용자 중심 개선
- 만족도 향상 → 재방문율 증가

---

### 🔮 5단계: 멀티모달 평가 (미래 계획)

#### 목표
텍스트뿐 아니라 음성, 표정, 제스처까지 분석

#### 기술 스택
- **음성 분석:** Google Speech-to-Text + 감정 분석 API
- **표정 분석:** OpenCV + MediaPipe (표정 인식)
- **제스처 분석:** Pose Estimation

#### 평가 항목 추가
- 목소리 크기 및 명료도
- 눈 맞춤
- 자세 (몸이 구부러지지 않았는지)
- 표정 (미소, 자신감)

#### 구현 난이도
- 높음 (6개월 이상 소요)
- 비용: 중간 (음성/영상 처리 비용)

#### 차별화 포인트
- 대부분의 AI 면접 서비스가 텍스트만 평가
- 실제 면접에 가장 가까운 피드백 제공

---

### ⚡ 6단계: 실시간 피드백

#### 목표
면접 중 실시간으로 개선 힌트 제공 (연습 모드에서만)

#### 구현 방법
1. 면접자 답변을 실시간으로 Streaming
2. 일정 단위(30초)마다 중간 평가
3. "더 구체적으로 말해보세요", "수치를 추가해보세요" 등 힌트 표시

#### 기대 효과
- 학습 효과 극대화
- 실전 면접 대비 능력 향상

#### 주의사항
- 실전 모드에서는 비활성화 (공정성)
- 힌트가 너무 직접적이면 학습 효과 저하

---

### 🏢 7단계: 도메인별 특화 평가

#### 목표
직무/산업별 맞춤 평가 기준 적용

#### 예시
- **개발직:** 기술 용어 정확성, 문제 해결 과정 중시
- **영업직:** 설득력, 숫자 기반 성과 중시
- **디자이너:** 포트폴리오 설명 능력, 디자인 철학
- **공기업:** STAR 기법 준수, 공공가치 부합도

#### 구현 방법
1. 직무별 루브릭 작성
2. 사용자가 직무 선택
3. 해당 직무 루브릭 적용

#### 기대 효과
- 직무 적합성 향상
- 차별화된 서비스

---

## 기술적 제약 및 고려사항

### 현재 제약사항

#### 1. API 할당량
- **Gemini API 무료 할당량:** 분당 15 요청, 일당 1500 요청
- **해결 방안:**
  - 유료 플랜 전환 ($0.00025/1K characters)
  - 캐싱 적용 (동일 질문 재사용)

#### 2. 응답 시간
- **현재:** 평균 5-10초
- **목표:** 3초 이내
- **개선 방안:**
  - Streaming 응답 적용
  - 프롬프트 최적화 (토큰 수 감소)

#### 3. 평가 주관성
- LLM 평가도 여전히 주관적
- **완화 방안:**
  - 여러 모델 앙상블 (GPT-4 + Gemini + Claude)
  - 사용자 피드백 반영

### 비용 추정 (월 1000명 사용 시)

| 항목 | 현재 | RAG 도입 | Fine-tuning |
|------|------|----------|-------------|
| API 비용 | $0 (무료) | $10-20 | $5-10 |
| 인프라 | $0 | $10 (Chroma) | $30 (GPU) |
| **총 비용** | **$0** | **$20-30** | **$35-40** |

### 개인정보 보호

#### GDPR/개인정보보호법 준수
1. 사용자 동의 없이 데이터 수집 금지
2. 수집 데이터 암호화 저장
3. 30일 후 자동 삭제 (또는 사용자 요청 시 즉시 삭제)

#### 구현 필요 사항
- 데이터 수집 동의 팝업
- 개인정보 처리방침 업데이트
- 데이터 삭제 API 구현

---

## 우선순위 요약

### 즉시 실행 (1개월 이내)
1. ✅ ~~프롬프트 엔지니어링~~ (완료)
2. ✅ ~~자동 평가 시스템~~ (완료)
3. 사용자 피드백 수집 UI 추가

### 단기 계획 (3개월 이내)
1. RAG 시스템 도입 (+30% 개선 예상)
2. 도메인별 특화 평가

### 중기 계획 (6개월 이내)
1. Fine-tuning (데이터 수집 병행)
2. 실시간 피드백 (연습 모드)

### 장기 계획 (1년 이내)
1. 멀티모달 평가 (음성, 표정)
2. 여러 모델 앙상블

---

## 참고 자료

### 내부 문서
- [평가 결과](./EVALUATION_RESULTS.md)
- [Before/After 비교](./PRESENTATION_COMPARISON.md)
- [발표 자료](./PRESENTATION_SUMMARY.md)
- [수동 평가 가이드](./MANUAL_FEEDBACK_EVALUATION.md)

### 외부 자료
- [Gemini API 문서](https://ai.google.dev/gemini-api/docs)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [LLM-as-a-Judge Paper](https://arxiv.org/abs/2306.05685)
- [RAG 구현 가이드](https://docs.trychroma.com/)

---

**최종 업데이트:** 2025-12-05
**문서 버전:** 1.0.0
**작성자:** Raon 개발팀
